# yaml-language-server: $schema=https://raw.githubusercontent.com/hubmapconsortium/hra-ui/main/apps/humanatlas.io/src/pages.schema.json

- type: header
  headerCard:
    - title: HRA Organ Gallery
      subtitle: An immersive application that allows users to explore 3D reference organs, anatomical structures, and cell types in virtual reality
      image: assets/images/vr_gallery.svg
      alt: HRA Organ Gallery icon

- type: announcement
  announcementCard:
    - message: "The 7th Release of the Human Reference Atlas (v2.1) is now available! See what's new in HRA v2.1 in "
      route: 'v2.1'
      routeText: '7th Release Notes.'
      emoji: 'üéâ'

- type: margin
  bottom: 3.5rem

- type: page-data
  pageData:
    - heading: Overview
      descriptions: |
        The Human Reference Atlas (HRA) Organ Gallery is a virtual reality (VR) application that enables users to explore 3D organ models of the HRA in their true size, location, and spatial relation to each other.
        The HRA Organ Gallery has two main use cases: 1) introducing both novice and expert users to the 2D and 3D data available in the HRA via the HuBMAP Data Portal, the SenNet Data Portal, and similar efforts, and 2) providing quality assurance and quality control (QA/QC) for HRA data providers.
        More use cases are under development. The concept of the application is described in this <a href="https://doi.org/10.3389/fbinf.2023.1162723" target="_blank">publication</a>.
        Figure 1 compares the user interface for exploring the HRA via the [Exploration User Interface (EUI)](https://apps.humanatlas.io/eui/) to how it appears in the HRA Organ Gallery when using a Meta Quest 2 or 3.
  styles:
    margin-bottom: 2rem

- type: button
  text: Use the HRA Organ Gallery
  url: https://www.meta.com/experiences/5696814507101529

- type: margin
  bottom: 5rem

- type: image
  imageSource: assets/images/OrganGallery.jpg
  alt: VR Organ Gallery
  styles:
    width: 100%

- type: page-data
  pageData:
    - heading: ''
      descriptions: |
        <strong>Figure 1.</strong>
        <span class="hra-bold"> 2D vs. VR. (A)</span>: A user looks at the HRA with the
        <a href="https://apps.humanatlas.io/eui/" target="_blank">Exploration User Interface</a> in a
        standard-size browser window on a 17-in display.
        <span class="hra-bold">(B)</span>: The HRA Organ Gallery allows the user to view the organs, tissue blocks, and cell type counts of the HRA in true scale using
        immersive technology (VR). [Source](https://doi.org/10.1101/2023.02.13.528002). More information can be found at our [README](https://github.com/cns-iu/hra-organ-gallery-in-vr/blob/main/README.md).

- type: page-data
  pageData:
    - heading: Background
      descriptions: |
        The HRA, funded by HuBMAP, SenNet, and similar efforts, aims to map the adult healthy human body at single-cell resolution through a collaboration across 17 (and counting) international consortia.
        The project includes three main categories of data: biological structure, spatial, and specimen data. The ASCT+B tables are compiled by experts to capture biological structure data, describing the connection between anatomical structures, cell types, and biomarkers.

- type: page-data
  pageData:
    - heading: Why Virtual Reality?
      descriptions: |
        Using a visually explicit method of data integration, the HRA enables users to explore disparate data. Virtual reality (VR) presents a unique opportunity to explore both spatial and abstract data in an immersive environment that enhances presence beyond traditional interfaces like windows, icons, menus, and pointers, also called WIMP paradigm (Van Dam, 1997). Although some users may be able to learn how to explore 3D reference organs and tissue blocks on a 2D screen (Bueckle et al., 2021, 2022), many still struggle with interacting with 3D objects on a 2D screen.

- type: page-data
  pageData:
    - heading: Data Visualizations
      descriptions: |
        The application's primary building blocks, presented in Figure 3 of <a href="https://doi.org/10.1101/2023.02.13.528002" target="blank">the preprint paper</a>, include the SceneBuilder which serves as the data manager for the application and retrieves data from the HRA API, and the DataLoader which uses Node, NodeArray, and GLBObject classes to store 3D organs in GLB format. Once the setup is complete, the user can interact with the organs, and the entire scene takes about 5-7 seconds to load when running natively on the Meta Quest 2 or 3. Through the HRA Organ Gallery, users can investigate 55 3D reference organs and 800+ mapped tissue blocks obtained from 300+ diverse donors and providers and 20+ tissue data providers (as of HRA v2.1), connected to 6000+ datasets, in a cohesive, immersive, and 3D VR environment at the convergence of VR, information visualization, and bioinformatics.

- type: page-data
  pageData:
    - heading: Feedback
      descriptions: |
        Information for test users is available <a href="https://github.com/cns-iu/hra-organ-gallery-in-vr/blob/main/INFORMATION_FOR_TESTERS.MD" target="_blank">here</a>. In order to engage a diverse group of users in the development of the HRA Organ Gallery, we request feedback from a broad range of specialists in fields such as bioinformatics, 3D modeling, medical illustration, anatomy, data curation, and biology. We are continuous evaluating the app's usability, engagement, and presence.

        Also, please email Andreas Bueckle (abueckle@iu.edu) if you are interested in contributing your input to the research and development of the HRA Organ Gallery.

- type: margin
  bottom: 5rem

- type: page-data
  pageData:
    - heading: References
      descriptions: |
        A. Bueckle, C. Qing, S. Luley, Y. Kumar, N. Pandey, and K. B√∂rner,
        ‚ÄúThe HRA Organ Gallery affords immersive superpowers for building and explorring the Human Reference Atlas with virtual reality,‚Äù
        Frontiers in Bioinformatics, vol. 3, 2023. doi: <a href="https://doi.org/10.3389/fbinf.2023.1162723" target="_blank">10.3389/fbinf.2023.1162723</a>

        Bueckle, Andreas., Kilian Buehling, Patrick C. Shih, and Katy B√∂rner. 2022.
        "<a href="https://www.frontiersin.org/articles/10.3389/frvir.2021.727344/full" target="_blank">
        Optimizing Performance and Satisfaction in Matching and Movement Tasks in Virtual Reality with Interventions Using the Data Visualization Literacy Framework</a>".
        <i>Frontiers in Virtual Reality</i> 2. doi: 10.3389/frvir.2021.727344.

        Bueckle, Andreas., Kilian Buehling, Patrick C. Shih, and Katy B√∂rner. 2021.
        "<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0258103" target="blank">3D Virtual Reality vs. 2D Desktop Registration User Interface Comparison</a>".
        <i>PLOS ONE</i> 16 (10): e0258103. doi: 10.1371/journal.pone.0258103.

        van Dam, Andries. 1997.
        "<a href="https://doi.org/10.1145/253671.253708" target="blank">Post-WIMP User Interfaces</a>".
        <i>Communications of the ACM</i> 40 (2): 63-67. doi: 10.1145/253671.253708.
